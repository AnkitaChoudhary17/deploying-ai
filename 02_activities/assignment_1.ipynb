{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f0928fd5",
      "metadata": {
        "id": "f0928fd5"
      },
      "source": [
        "# Deploying AI\n",
        "## Assignment 1: Evaluating Summaries"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8f3586e4",
      "metadata": {
        "id": "8f3586e4"
      },
      "source": [
        "A key application of LLMs is to summarize documents. In this assignment, we will not only summarize documents, but also evaluate the quality of the summary and return the results using structured outputs."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "609f2fa2",
      "metadata": {
        "id": "609f2fa2"
      },
      "source": [
        "**Instructions:** please complete the sections below stating any relevant decisions that you have made and showing the code substantiating your solution."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "604f0601",
      "metadata": {
        "id": "604f0601"
      },
      "source": [
        "## Select a Document\n",
        "\n",
        "Please select one out of the following articles:\n",
        "\n",
        "+ [Managing Oneself, by Peter Druker](https://www.thecompleteleader.org/sites/default/files/imce/Managing%20Oneself_Drucker_HBR.pdf)  (PDF)\n",
        "+ [The GenAI Divide: State of AI in Business 2025](https://www.artificialintelligence-news.com/wp-content/uploads/2025/08/ai_report_2025.pdf) (PDF)\n",
        "+ [What is Noise?, by Alex Ross](https://www.newyorker.com/magazine/2024/04/22/what-is-noise) (Web)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c125d1e",
      "metadata": {
        "id": "2c125d1e"
      },
      "source": [
        "# Load Secrets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b8dbcc48",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8dbcc48",
        "outputId": "e9ca3306-345d-4ca2-b585-96a934ffafed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cannot find .env file\n"
          ]
        }
      ],
      "source": [
        "%load_ext dotenv\n",
        "%dotenv ../05_src/.secrets"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b036115",
      "metadata": {
        "id": "7b036115"
      },
      "source": [
        "## Load Document\n",
        "\n",
        "Depending on your choice, you can consult the appropriate set of functions below. Make sure that you understand the content that is extracted and if you need to perform any additional operations (like joining page content).\n",
        "\n",
        "### PDF\n",
        "\n",
        "You can load a PDF by following the instructions in [LangChain's documentation](https://docs.langchain.com/oss/python/langchain/knowledge-base#loading-documents). Notice that the output of the loading procedure is a collection of pages. You can join the pages by using the code below.\n",
        "\n",
        "```python\n",
        "document_text = \"\"\n",
        "for page in docs:\n",
        "    document_text += page.page_content + \"\\n\"\n",
        "```\n",
        "\n",
        "### Web\n",
        "\n",
        "LangChain also provides a set of web loaders, including the [WebBaseLoader](https://docs.langchain.com/oss/python/integrations/document_loaders/web_base). You can use this function to load web pages."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-community pypdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2a1YVMJApVq",
        "outputId": "111179f9-0ab3-4a69-cdef-0fcbe6cddfb4"
      },
      "id": "b2a1YVMJApVq",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.12/dist-packages (0.4.1)\n",
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.12/dist-packages (6.7.0)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (1.2.9)\n",
            "Requirement already satisfied: langchain-classic<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (1.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.46)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.32.5 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.32.5)\n",
            "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (6.0.3)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (3.13.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (9.1.3)\n",
            "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.12.0)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.6.9)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.3)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.7.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.22.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (3.26.2)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<2.0.0,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-classic<2.0.0,>=1.0.0->langchain-community) (1.1.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain-classic<2.0.0,>=1.0.0->langchain-community) (2.12.3)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.1->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.1->langchain-community) (26.0)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.1->langchain-community) (4.15.0)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.1->langchain-community) (0.14.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (3.11.7)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: xxhash>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (3.6.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.25.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.2.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2026.1.4)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community) (3.3.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (4.12.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.1->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-classic<2.0.0,>=1.0.0->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-classic<2.0.0,>=1.0.0->langchain-community) (2.41.4)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community) (1.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "256159db",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "256159db",
        "outputId": "70cb3b6a-7b9d-4f08-b08b-2957386f9d4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Document loaded! Length: 51456\n"
          ]
        }
      ],
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "\n",
        "loader = PyPDFLoader(\"Managing Oneself_Drucker_HBR.pdf\")\n",
        "docs = loader.load()\n",
        "\n",
        "document_text = \"\"\n",
        "for page in docs:\n",
        "    document_text += page.page_content + \"\\n\"\n",
        "\n",
        "print(\"Document loaded! Length:\", len(document_text))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6951b9f3",
      "metadata": {
        "id": "6951b9f3"
      },
      "source": [
        "## Generation Task\n",
        "\n",
        "Using the OpenAI SDK, please create a **structured outut** with the following specifications:\n",
        "\n",
        "+ Use a model that is NOT in the GPT-5 family.\n",
        "+ Output should be a Pydantic BaseModel object. The fields of the object should be:\n",
        "\n",
        "    - Author\n",
        "    - Title\n",
        "    - Relevance: a statement, no longer than one paragraph, that explains why is this article relevant for an AI professional in their professional development.\n",
        "    - Summary: a concise and succinct summary no longer than 1000 tokens.\n",
        "    - Tone: the tone used to produce the summary (see below).\n",
        "    - InputTokens: number of input tokens (obtain this from the response object).\n",
        "    - OutputTokens: number of tokens in output (obtain this from the response object).\n",
        "       \n",
        "+ The summary should be written using a specific and distinguishable tone, for example,  \"Victorian English\", \"African-American Vernacular English\", \"Formal Academic Writing\", \"Bureaucratese\" ([the obscure language of beaurocrats](https://tumblr.austinkleon.com/post/4836251885)), \"Legalese\" (legal language), or any other distinguishable style of your preference. Make sure that the style is something you can identify.\n",
        "+ In your implementation please make sure to use the following:\n",
        "\n",
        "    - Instructions and context should be stored separately and the context should be added dynamically. Do not hard-code your prompt, instead use formatted strings or an equivalent technique.\n",
        "    - Use the developer (instructions) prompt and the user prompt.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from pydantic import BaseModel\n",
        "from openai import OpenAI\n",
        "import os\n",
        "\n",
        "# Define structured output\n",
        "class SummaryOutput(BaseModel):\n",
        "    Author: str\n",
        "    Title: str\n",
        "    Relevance: str\n",
        "    Summary: str\n",
        "    Tone: str\n",
        "    InputTokens: int\n",
        "    OutputTokens: int\n",
        "\n",
        "# Initialize OpenAI client\n",
        "client = OpenAI(\n",
        "    api_key=OPENAI_API_KEY\n",
        ")\n",
        "\n",
        "\n",
        "# System instruction\n",
        "dev_prompt = \"\"\"\n",
        "Summarize documents as JSON with fields:\n",
        "Author, Title, Relevance, Summary, Tone.\n",
        "\n",
        "Tone must be clearly defined.\n",
        "Return valid JSON only.\n",
        "\"\"\"\n",
        "\n",
        "# User prompt\n",
        "user_prompt = f\"\"\"\n",
        "Please analyze and condense the following document using formal academic language.\n",
        "\n",
        "Your summary must include:\n",
        "1. Author name\n",
        "2. Document title\n",
        "3. Why this material matters to AI professionals\n",
        "4. Concise overview (max 1000 tokens)\n",
        "5. Tone classification\n",
        "\n",
        "Document:\n",
        "{document_text}\n",
        "\"\"\"\n",
        "\n",
        "# Call GPT-4o-mini\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    temperature=0.3,\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": dev_prompt},\n",
        "        {\"role\": \"user\", \"content\": user_prompt}\n",
        "    ],\n",
        "    response_format={\"type\": \"json_object\"}\n",
        ")\n",
        "\n",
        "# Parse result\n",
        "summary_data = json.loads(response.choices[0].message.content)\n",
        "\n",
        "# Add token usage\n",
        "summary_data[\"InputTokens\"] = response.usage.prompt_tokens\n",
        "summary_data[\"OutputTokens\"] = response.usage.completion_tokens\n",
        "\n",
        "# Convert to structured model\n",
        "summary = SummaryOutput(**summary_data)\n",
        "\n",
        "# Print result\n",
        "print(summary.model_dump_json(indent=2))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rhruINFlCQuP",
        "outputId": "e30ebb10-e381-4b64-8569-ad43edc7e56a"
      },
      "id": "rhruINFlCQuP",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"Author\": \"Peter F. Drucker\",\n",
            "  \"Title\": \"Managing Oneself\",\n",
            "  \"Relevance\": \"This material is crucial for AI professionals as it emphasizes the importance of self-awareness, personal strengths, and adaptability in a rapidly evolving work environment, which is particularly relevant in the context of AI and knowledge work.\",\n",
            "  \"Summary\": \"In 'Managing Oneself', Peter F. Drucker argues that success in the knowledge economy hinges on individuals' ability to understand their strengths, weaknesses, values, and preferred work styles. He posits that knowledge workers must take responsibility for their own careers, acting as their own CEOs. Drucker outlines a series of introspective questions that individuals should ask themselves to identify their strengths, preferred methods of working, and ethical values. He emphasizes the importance of feedback analysis to accurately assess one's abilities and suggests that individuals focus on enhancing their strengths rather than attempting to improve weaknesses. Drucker also discusses the significance of aligning personal values with organizational values to ensure job satisfaction and effectiveness. He concludes by highlighting the necessity for knowledge workers to manage their careers proactively, especially in a world where traditional career paths are increasingly obsolete. The document serves as a guide for individuals seeking to navigate their professional lives with intention and purpose, particularly in the context of the knowledge economy.\",\n",
            "  \"Tone\": \"Formal and instructive\",\n",
            "  \"InputTokens\": 12242,\n",
            "  \"OutputTokens\": 272\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ec1e63f8",
      "metadata": {
        "id": "ec1e63f8"
      },
      "source": [
        "# Evaluate the Summary\n",
        "\n",
        "Use the DeepEval library to evaluate the **summary** as follows:\n",
        "\n",
        "+ Summarization Metric:\n",
        "\n",
        "    - Use the [Summarization metric](https://deepeval.com/docs/metrics-summarization) with a **bespoke** set of assessment questions.\n",
        "    - Please use, at least, five assessment questions.\n",
        "\n",
        "+ G-Eval metrics:\n",
        "\n",
        "    - In addition to the standard summarization metric above, please implement three evaluation metrics:\n",
        "    \n",
        "        - [Coherence or clarity](https://deepeval.com/docs/metrics-llm-evals#coherence)\n",
        "        - [Tonality](https://deepeval.com/docs/metrics-llm-evals#tonality)\n",
        "        - [Safety](https://deepeval.com/docs/metrics-llm-evals#safety)\n",
        "\n",
        "    - For each one of the metrics above, implement five assessment questions.\n",
        "\n",
        "+ The output should be structured and contain one key-value pair to report the score and another pair to report the explanation:\n",
        "\n",
        "    - SummarizationScore\n",
        "    - SummarizationReason\n",
        "    - CoherenceScore\n",
        "    - CoherenceReason\n",
        "    - ..."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install deepeval"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ngh9tdElHAdn",
        "outputId": "86e700e8-3ded-4b0b-9f67-36254252e759"
      },
      "id": "Ngh9tdElHAdn",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: deepeval in /usr/local/lib/python3.12/dist-packages (3.8.4)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from deepeval) (3.13.3)\n",
            "Requirement already satisfied: click<8.3.0,>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from deepeval) (8.2.1)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.67.1 in /usr/local/lib/python3.12/dist-packages (from deepeval) (1.76.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from deepeval) (3.1.6)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.12/dist-packages (from deepeval) (1.6.0)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (from deepeval) (2.17.0)\n",
            "Requirement already satisfied: opentelemetry-api<2.0.0,>=1.24.0 in /usr/local/lib/python3.12/dist-packages (from deepeval) (1.39.1)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0 in /usr/local/lib/python3.12/dist-packages (from deepeval) (1.39.1)\n",
            "Requirement already satisfied: opentelemetry-sdk<2.0.0,>=1.24.0 in /usr/local/lib/python3.12/dist-packages (from deepeval) (1.39.1)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.12/dist-packages (from deepeval) (3.2.0)\n",
            "Requirement already satisfied: posthog<6.0.0,>=5.4.0 in /usr/local/lib/python3.12/dist-packages (from deepeval) (5.4.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.11.7 in /usr/local/lib/python3.12/dist-packages (from deepeval) (2.12.3)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from deepeval) (2.12.0)\n",
            "Requirement already satisfied: pyfiglet in /usr/local/lib/python3.12/dist-packages (from deepeval) (1.0.4)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.12/dist-packages (from deepeval) (8.4.2)\n",
            "Requirement already satisfied: pytest-asyncio in /usr/local/lib/python3.12/dist-packages (from deepeval) (1.3.0)\n",
            "Requirement already satisfied: pytest-repeat in /usr/local/lib/python3.12/dist-packages (from deepeval) (0.9.4)\n",
            "Requirement already satisfied: pytest-rerunfailures in /usr/local/lib/python3.12/dist-packages (from deepeval) (16.1)\n",
            "Requirement already satisfied: pytest-xdist in /usr/local/lib/python3.12/dist-packages (from deepeval) (3.8.0)\n",
            "Requirement already satisfied: python-dotenv<2.0.0,>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from deepeval) (1.2.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.31.0 in /usr/local/lib/python3.12/dist-packages (from deepeval) (2.32.5)\n",
            "Requirement already satisfied: rich<15.0.0,>=13.6.0 in /usr/local/lib/python3.12/dist-packages (from deepeval) (13.9.4)\n",
            "Requirement already satisfied: sentry-sdk in /usr/local/lib/python3.12/dist-packages (from deepeval) (2.52.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from deepeval) (75.2.0)\n",
            "Requirement already satisfied: tabulate<0.10.0,>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from deepeval) (0.9.0)\n",
            "Requirement already satisfied: tenacity<=10.0.0,>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from deepeval) (9.1.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.12/dist-packages (from deepeval) (4.67.3)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.9 in /usr/local/lib/python3.12/dist-packages (from deepeval) (0.21.1)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.12/dist-packages (from deepeval) (0.46.3)\n",
            "Requirement already satisfied: typing-extensions~=4.12 in /usr/local/lib/python3.12/dist-packages (from grpcio<2.0.0,>=1.67.1->deepeval) (4.15.0)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api<2.0.0,>=1.24.0->deepeval) (8.7.1)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.57 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0->deepeval) (1.72.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.39.1 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0->deepeval) (1.39.1)\n",
            "Requirement already satisfied: opentelemetry-proto==1.39.1 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0->deepeval) (1.39.1)\n",
            "Requirement already satisfied: protobuf<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-proto==1.39.1->opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0->deepeval) (5.29.6)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.60b1 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-sdk<2.0.0,>=1.24.0->deepeval) (0.60b1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from posthog<6.0.0,>=5.4.0->deepeval) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.2 in /usr/local/lib/python3.12/dist-packages (from posthog<6.0.0,>=5.4.0->deepeval) (2.9.0.post0)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from posthog<6.0.0,>=5.4.0->deepeval) (2.2.1)\n",
            "Requirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from posthog<6.0.0,>=5.4.0->deepeval) (1.9.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.11.7->deepeval) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.11.7->deepeval) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.11.7->deepeval) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.31.0->deepeval) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.31.0->deepeval) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.31.0->deepeval) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.31.0->deepeval) (2026.1.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich<15.0.0,>=13.6.0->deepeval) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich<15.0.0,>=13.6.0->deepeval) (2.19.2)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0.0,>=0.9->deepeval) (1.5.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->deepeval) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->deepeval) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->deepeval) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->deepeval) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->deepeval) (6.7.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->deepeval) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->deepeval) (1.22.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->deepeval) (3.0.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai->deepeval) (4.12.1)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai->deepeval) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai->deepeval) (0.13.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai->deepeval) (1.3.1)\n",
            "Requirement already satisfied: iniconfig>=1 in /usr/local/lib/python3.12/dist-packages (from pytest->deepeval) (2.3.0)\n",
            "Requirement already satisfied: packaging>=20 in /usr/local/lib/python3.12/dist-packages (from pytest->deepeval) (26.0)\n",
            "Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.12/dist-packages (from pytest->deepeval) (1.6.0)\n",
            "Requirement already satisfied: execnet>=2.1 in /usr/local/lib/python3.12/dist-packages (from pytest-xdist->deepeval) (2.1.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai->deepeval) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai->deepeval) (0.16.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api<2.0.0,>=1.24.0->deepeval) (3.23.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich<15.0.0,>=13.6.0->deepeval) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99560b73",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285,
          "referenced_widgets": [
            "cdc269ba07e547e7aeabf6e4cc2fac70",
            "5e996d8f77124784ad1dee02fd702984",
            "56eb883689ee40a2b929b87519fe344b",
            "721b492060dd41ac944d8699fe771357",
            "c9b2e59bec91485a92ebc0a653360100",
            "9eaad4447956483f8b827117a8e956d2",
            "748152d3fa4443ea97b05f407858f3fb",
            "bc1a25ec4fa64041b92fb3c4b7597f55"
          ]
        },
        "id": "99560b73",
        "outputId": "4679ad57-4df3-4a80-806a-b865362a25e6"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cdc269ba07e547e7aeabf6e4cc2fac70"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "Using OpenAI Model: gpt-4o-mini\n",
            "============================================================\n",
            "Evaluating content_quality...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "56eb883689ee40a2b929b87519fe344b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score: 0.750\n",
            "Evaluating logical_flow...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c9b2e59bec91485a92ebc0a653360100"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score: 0.862\n",
            "Evaluating style_consistency...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "748152d3fa4443ea97b05f407858f3fb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score: 0.887\n",
            "Evaluating content_safety...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score: 0.917\n",
            "\n",
            "Results:\n",
            "{'SummarizationScore': 0.75, 'CoherenceScore': 0.8622459331201855, 'TonalityScore': 0.8867035747777032, 'SafetyScore': 0.9167815710469119}\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from deepeval.metrics import GEval, SummarizationMetric\n",
        "from deepeval.test_case import LLMTestCase, LLMTestCaseParams\n",
        "\n",
        "\n",
        "\n",
        "class DocumentSummaryEvaluator:\n",
        "    \"\"\"\n",
        "    Comprehensive evaluation system using OpenAI models via DeepEval.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, target_tone, openai_api_key=OPENAI_API_KEY):\n",
        "        \"\"\"\n",
        "        Initialize evaluator with fixed OpenAI API key.\n",
        "        \"\"\"\n",
        "\n",
        "        self.target_tone = target_tone\n",
        "\n",
        "        # Use fixed API key\n",
        "        self.openai_api_key = openai_api_key\n",
        "\n",
        "        if not self.openai_api_key:\n",
        "            raise ValueError(\"OPENAI_API_KEY must be provided\")\n",
        "\n",
        "        # Set for DeepEval\n",
        "        os.environ[\"OPENAI_API_KEY\"] = self.openai_api_key\n",
        "\n",
        "        # Evaluation model\n",
        "        self.evaluation_model = \"gpt-4o-mini\"\n",
        "\n",
        "        self.metric_collection = {}\n",
        "        self.evaluation_results = {}\n",
        "\n",
        "        self._setup_evaluation_metrics()\n",
        "\n",
        "    def _setup_evaluation_metrics(self):\n",
        "\n",
        "        self.metric_collection['content_quality'] = SummarizationMetric(\n",
        "            threshold=0.5,\n",
        "            model=self.evaluation_model,\n",
        "            assessment_questions=[\n",
        "                \"Are the core principles clearly presented?\",\n",
        "                \"Are key strategies accurately conveyed?\",\n",
        "                \"Are real-world applications mentioned?\",\n",
        "                \"Is professional development relevance explained?\",\n",
        "                \"Is summary concise yet comprehensive?\",\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        self.metric_collection['logical_flow'] = GEval(\n",
        "            name=\"LogicalFlow\",\n",
        "            criteria=\"Evaluate logical structure, clarity, and coherence.\",\n",
        "            evaluation_steps=[\n",
        "                \"Check logical ordering\",\n",
        "                \"Check transitions\",\n",
        "                \"Check clarity\",\n",
        "                \"Check structural coherence\",\n",
        "                \"Check comprehension quality\"\n",
        "            ],\n",
        "            evaluation_params=[LLMTestCaseParams.ACTUAL_OUTPUT],\n",
        "            threshold=0.5,\n",
        "            model=self.evaluation_model,\n",
        "        )\n",
        "\n",
        "        self.metric_collection['style_consistency'] = GEval(\n",
        "            name=\"StyleConsistency\",\n",
        "            criteria=f\"Evaluate adherence to {self.target_tone}\",\n",
        "            evaluation_steps=[\n",
        "                \"Check vocabulary formality\",\n",
        "                \"Check grammar complexity\",\n",
        "                \"Check tone consistency\",\n",
        "                \"Check professional style\",\n",
        "                \"Check authenticity\"\n",
        "            ],\n",
        "            evaluation_params=[LLMTestCaseParams.ACTUAL_OUTPUT],\n",
        "            threshold=0.5,\n",
        "            model=self.evaluation_model,\n",
        "        )\n",
        "\n",
        "        self.metric_collection['content_safety'] = GEval(\n",
        "            name=\"ContentSafety\",\n",
        "            criteria=\"Evaluate ethical, safe, unbiased language.\",\n",
        "            evaluation_steps=[\n",
        "                \"Check harmful content\",\n",
        "                \"Check bias\",\n",
        "                \"Check professionalism\",\n",
        "                \"Check factual integrity\",\n",
        "                \"Check respectful tone\"\n",
        "            ],\n",
        "            evaluation_params=[LLMTestCaseParams.ACTUAL_OUTPUT],\n",
        "            threshold=0.7,\n",
        "            model=self.evaluation_model,\n",
        "        )\n",
        "\n",
        "    def run_comprehensive_evaluation(self, source_document, generated_summary):\n",
        "\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(f\"Using OpenAI Model: {self.evaluation_model}\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        test_case = LLMTestCase(\n",
        "            input=source_document,\n",
        "            actual_output=generated_summary,\n",
        "        )\n",
        "\n",
        "        for metric_name, metric in self.metric_collection.items():\n",
        "\n",
        "            print(f\"Evaluating {metric_name}...\")\n",
        "\n",
        "            try:\n",
        "\n",
        "                metric.measure(test_case)\n",
        "\n",
        "                self.evaluation_results[metric_name] = {\n",
        "                    \"score\": metric.score,\n",
        "                    \"reason\": metric.reason,\n",
        "                    \"passed\": metric.score >= metric.threshold\n",
        "                }\n",
        "\n",
        "                print(f\"Score: {metric.score:.3f}\")\n",
        "\n",
        "            except Exception as e:\n",
        "\n",
        "                self.evaluation_results[metric_name] = {\n",
        "                    \"score\": None,\n",
        "                    \"reason\": str(e),\n",
        "                    \"passed\": False\n",
        "                }\n",
        "\n",
        "        return self._generate_structured_output()\n",
        "\n",
        "    def _generate_structured_output(self):\n",
        "\n",
        "        return {\n",
        "            \"SummarizationScore\": self.evaluation_results.get(\n",
        "                \"content_quality\", {}).get(\"score\"),\n",
        "\n",
        "            \"CoherenceScore\": self.evaluation_results.get(\n",
        "                \"logical_flow\", {}).get(\"score\"),\n",
        "\n",
        "            \"TonalityScore\": self.evaluation_results.get(\n",
        "                \"style_consistency\", {}).get(\"score\"),\n",
        "\n",
        "            \"SafetyScore\": self.evaluation_results.get(\n",
        "                \"content_safety\", {}).get(\"score\"),\n",
        "        }\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    evaluator = DocumentSummaryEvaluator(\n",
        "        target_tone=\"Formal Academic Writing\"\n",
        "    )\n",
        "\n",
        "    results = evaluator.run_comprehensive_evaluation(\n",
        "        document_text,\n",
        "        summary.Summary\n",
        "    )\n",
        "\n",
        "    print(\"\\nResults:\")\n",
        "    print(results)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c000bb60",
      "metadata": {
        "id": "c000bb60"
      },
      "source": [
        "# Enhancement\n",
        "\n",
        "Of course, evaluation is important, but we want our system to self-correct.  \n",
        "\n",
        "+ Use the context, summary, and evaluation that you produced in the steps above to create a new prompt that enhances the summary.\n",
        "+ Evaluate the new summary using the same function.\n",
        "+ Report your results. Did you get a better output? Why? Do you think these controls are enough?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4cf01e4f",
      "metadata": {
        "id": "4cf01e4f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fd18c91-9587-4f61-9a45-436eac55db55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Improved Summary:\n",
            "\n",
            "In \"Managing Oneself,\" Peter F. Drucker argues that success in the knowledge economy depends on individuals' ability to understand their strengths, weaknesses, values, and preferred work styles. He posits that knowledge workers must take responsibility for their own careers, effectively acting as their own CEOs. Drucker outlines a series of introspective questions that individuals should ask themselves to identify their strengths, preferred methods of working, and ethical values. He emphasizes the importance of feedback analysis as a tool for accurately assessing one's abilities and suggests that individuals focus on enhancing their strengths rather than attempting to improve their weaknesses. Additionally, Drucker discusses the significance of aligning personal values with organizational values to ensure job satisfaction and effectiveness. He concludes by highlighting the necessity for knowledge workers to proactively manage their careers, particularly in a world where traditional career paths are increasingly obsolete. This document serves as a guide for individuals seeking to navigate their professional lives with intention and purpose, especially within the context of the knowledge economy.\n"
          ]
        }
      ],
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(api_key=OPENAI_API_KEY)\n",
        "\n",
        "\n",
        "def generate_improved_summary(context, original_summary, evaluation_results):\n",
        "\n",
        "    improvement_prompt = f\"\"\"\n",
        "                  You are an expert academic editor performing minimal revision.\n",
        "\n",
        "                    Your goal is to improve clarity, coherence, and tone while preserving all factual content.\n",
        "\n",
        "                    STRICT RULES:\n",
        "                    - Change only sentences that are unclear or poorly structured.\n",
        "                    - Keep sentences that are already clear and correct.\n",
        "                    - Do NOT add new information.\n",
        "                    - Do NOT remove correct information.\n",
        "                    - Do NOT rewrite unnecessarily.\n",
        "\n",
        "                    ORIGINAL DOCUMENT:\n",
        "                    {context}\n",
        "\n",
        "                    CURRENT SUMMARY:\n",
        "                    {summary}\n",
        "\n",
        "                    Return ONLY the revised summary.\n",
        "                  \"\"\"\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        temperature=0.1,\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": \"You revise summaries conservatively. You never hallucinate or invent information.\"\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": improvement_prompt\n",
        "            }\n",
        "        ],\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "\n",
        "#print the improved summary\n",
        "improved_summary = generate_improved_summary(\n",
        "    document_text,\n",
        "    summary.Summary,\n",
        "    results\n",
        ")\n",
        "\n",
        "print(\"\\nImproved Summary:\\n\")\n",
        "print(improved_summary)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evluating the improved results using the same metrics\n",
        "improved_results = evaluator.run_comprehensive_evaluation(\n",
        "    document_text,\n",
        "    improved_summary\n",
        ")\n",
        "\n",
        "print(\"\\nImproved Results:\")\n",
        "print(improved_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285,
          "referenced_widgets": [
            "57b5f80a02e24d1595bf4ff5d9fccdff",
            "4c6e4256003a40c49b32b12c370686b2",
            "5ad0d49398c549aead4cf6d4ce169533",
            "39b496033ca14b709c7578ce40461e3a",
            "bdaf769dd4dc40a29d8a8908362b6db1",
            "8194784edb9d4764aa6fb65308f1d57f",
            "eb28f9c82df243a4a817ce3ce76ad546",
            "293df2f42b6c4eb69e8accf98357a72c"
          ]
        },
        "id": "22JXruRpL2CL",
        "outputId": "f856e98f-33e4-45e9-aa1b-1995d5f92008"
      },
      "id": "22JXruRpL2CL",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "57b5f80a02e24d1595bf4ff5d9fccdff"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "Using OpenAI Model: gpt-4o-mini\n",
            "============================================================\n",
            "Evaluating content_quality...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5ad0d49398c549aead4cf6d4ce169533"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score: 0.750\n",
            "Evaluating logical_flow...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bdaf769dd4dc40a29d8a8908362b6db1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score: 0.868\n",
            "Evaluating style_consistency...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eb28f9c82df243a4a817ce3ce76ad546"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score: 0.890\n",
            "Evaluating content_safety...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score: 0.905\n",
            "\n",
            "Improved Results:\n",
            "{'SummarizationScore': 0.75, 'CoherenceScore': 0.8679178692681615, 'TonalityScore': 0.8904650542170278, 'SafetyScore': 0.904552344397195}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#comparing the two results\n",
        "def compare_results(old, new):\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"COMPARISON REPORT\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    for metric in old.keys():\n",
        "\n",
        "        old_score = old[metric]\n",
        "        new_score = new[metric]\n",
        "\n",
        "        if old_score is None or new_score is None:\n",
        "            continue\n",
        "\n",
        "        diff = new_score - old_score\n",
        "\n",
        "        print(f\"{metric}\")\n",
        "        print(f\"  Old: {old_score:.3f}\")\n",
        "        print(f\"  New: {new_score:.3f}\")\n",
        "        print(f\"  Change: {diff:+.3f}\")\n",
        "\n",
        "        if diff > 0:\n",
        "            print(\"  Improvement\")\n",
        "        elif diff < 0:\n",
        "            print(\"  Worse\")\n",
        "        else:\n",
        "            print(\"  No change\")\n",
        "\n",
        "        print()\n",
        "\n",
        "compare_results(results, improved_results)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6xWIDswCL-bd",
        "outputId": "20222858-c22d-429a-bc96-1e1d51c2d96d"
      },
      "id": "6xWIDswCL-bd",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "COMPARISON REPORT\n",
            "============================================================\n",
            "SummarizationScore\n",
            "  Old: 0.750\n",
            "  New: 0.750\n",
            "  Change: +0.000\n",
            "  No change\n",
            "\n",
            "CoherenceScore\n",
            "  Old: 0.862\n",
            "  New: 0.868\n",
            "  Change: +0.006\n",
            "  Improvement\n",
            "\n",
            "TonalityScore\n",
            "  Old: 0.887\n",
            "  New: 0.890\n",
            "  Change: +0.004\n",
            "  Improvement\n",
            "\n",
            "SafetyScore\n",
            "  Old: 0.917\n",
            "  New: 0.905\n",
            "  Change: -0.012\n",
            "  Worse\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "14d0de25",
      "metadata": {
        "id": "14d0de25"
      },
      "source": [
        ">The improved summary showed only minor changes. Coherence and tonality improved slightly, but the summarization score remained unchanged, indicating no meaningful gain in content completeness. The safety score decreased slightly, suggesting the revision introduced less optimal phrasing. Overall, the controls helped maintain stability and refine style but were not sufficient to significantly improve summary quality. I think stronger constraints, targeted feedback, or iterative refinement will be needed for further improvement.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "98e81f47",
      "metadata": {
        "id": "98e81f47"
      },
      "source": [
        "\n",
        "# Submission Information\n",
        "\n",
        " **Please review our [Assignment Submission Guide](https://github.com/UofT-DSI/onboarding/blob/main/onboarding_documents/submissions.md)**  for detailed instructions on how to format, branch, and submit your work. Following these guidelines is crucial for your submissions to be evaluated correctly.\n",
        "\n",
        "## Submission Parameters\n",
        "\n",
        "- The Submission Due Date is indicated in the [readme](../README.md#schedule) file.\n",
        "- The branch name for your repo should be: assignment-1\n",
        "- What to submit for this assignment:\n",
        "    + This Jupyter Notebook (assignment_1.ipynb) should be populated and should be the only change in your pull request.\n",
        "- What the pull request link should look like for this assignment: `https://github.com/<your_github_username>/production/pull/<pr_id>`\n",
        "    + Open a private window in your browser. Copy and paste the link to your pull request into the address bar. Make sure you can see your pull request properly. This helps the technical facilitator and learning support staff review your submission easily.\n",
        "\n",
        "## Checklist\n",
        "\n",
        "+ Created a branch with the correct naming convention.\n",
        "+ Ensured that the repository is public.\n",
        "+ Reviewed the PR description guidelines and adhered to them.\n",
        "+ Verify that the link is accessible in a private browser window.\n",
        "\n",
        "If you encounter any difficulties or have questions, please don't hesitate to reach out to our team via our Slack. Our Technical Facilitators and Learning Support staff are here to help you navigate any challenges.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": []
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "cdc269ba07e547e7aeabf6e4cc2fac70": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_5e996d8f77124784ad1dee02fd702984",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "\u001b[38;2;106;0;255m\u001b[0m \u001b[38;5;237m\u001b[0m  You're running DeepEval's latest \u001b[38;2;106;0;255mSummarization Metric\u001b[0m! \u001b[38;2;55;65;81m(using gpt-4o-mini, strict=False, async_mode=True)...\u001b[0m\n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #6a00ff; text-decoration-color: #6a00ff\"></span> <span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\"></span>  You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Summarization Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151\">(using gpt-4o-mini, strict=False, async_mode=True)...</span>\n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "5e996d8f77124784ad1dee02fd702984": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56eb883689ee40a2b929b87519fe344b": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_721b492060dd41ac944d8699fe771357",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": " You're running DeepEval's latest \u001b[38;2;106;0;255mLogicalFlow [GEval] Metric\u001b[0m! \u001b[38;2;55;65;81m(using gpt-4o-mini, strict=False, async_mode=True)\u001b[0m\n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">LogicalFlow [GEval] Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151\">(using gpt-4o-mini, strict=False, async_mode=True)</span>\n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "721b492060dd41ac944d8699fe771357": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9b2e59bec91485a92ebc0a653360100": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_9eaad4447956483f8b827117a8e956d2",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": " You're running DeepEval's latest \u001b[38;2;106;0;255mStyleConsistency [GEval] Metric\u001b[0m! \u001b[38;2;55;65;81m(using gpt-4o-mini, strict=False, async_mode=\u001b[0m\n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">StyleConsistency [GEval] Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151\">(using gpt-4o-mini, strict=False, async_mode=</span>\n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "9eaad4447956483f8b827117a8e956d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "748152d3fa4443ea97b05f407858f3fb": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_bc1a25ec4fa64041b92fb3c4b7597f55",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": " You're running DeepEval's latest \u001b[38;2;106;0;255mContentSafety [GEval] Metric\u001b[0m! \u001b[38;2;55;65;81m(using gpt-4o-mini, strict=False, async_mode=Tru\u001b[0m\n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">ContentSafety [GEval] Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151\">(using gpt-4o-mini, strict=False, async_mode=Tru</span>\n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "bc1a25ec4fa64041b92fb3c4b7597f55": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57b5f80a02e24d1595bf4ff5d9fccdff": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_4c6e4256003a40c49b32b12c370686b2",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "\u001b[38;2;106;0;255m\u001b[0m \u001b[38;5;237m\u001b[0m  You're running DeepEval's latest \u001b[38;2;106;0;255mSummarization Metric\u001b[0m! \u001b[38;2;55;65;81m(using gpt-4o-mini, strict=False, async_mode=True)...\u001b[0m\n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #6a00ff; text-decoration-color: #6a00ff\"></span> <span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\"></span>  You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Summarization Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151\">(using gpt-4o-mini, strict=False, async_mode=True)...</span>\n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "4c6e4256003a40c49b32b12c370686b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ad0d49398c549aead4cf6d4ce169533": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_39b496033ca14b709c7578ce40461e3a",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": " You're running DeepEval's latest \u001b[38;2;106;0;255mLogicalFlow [GEval] Metric\u001b[0m! \u001b[38;2;55;65;81m(using gpt-4o-mini, strict=False, async_mode=True)\u001b[0m\n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">LogicalFlow [GEval] Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151\">(using gpt-4o-mini, strict=False, async_mode=True)</span>\n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "39b496033ca14b709c7578ce40461e3a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bdaf769dd4dc40a29d8a8908362b6db1": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_8194784edb9d4764aa6fb65308f1d57f",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": " You're running DeepEval's latest \u001b[38;2;106;0;255mStyleConsistency [GEval] Metric\u001b[0m! \u001b[38;2;55;65;81m(using gpt-4o-mini, strict=False, async_mode=\u001b[0m\n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">StyleConsistency [GEval] Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151\">(using gpt-4o-mini, strict=False, async_mode=</span>\n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "8194784edb9d4764aa6fb65308f1d57f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb28f9c82df243a4a817ce3ce76ad546": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_293df2f42b6c4eb69e8accf98357a72c",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": " You're running DeepEval's latest \u001b[38;2;106;0;255mContentSafety [GEval] Metric\u001b[0m! \u001b[38;2;55;65;81m(using gpt-4o-mini, strict=False, async_mode=Tru\u001b[0m\n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">ContentSafety [GEval] Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151\">(using gpt-4o-mini, strict=False, async_mode=Tru</span>\n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "293df2f42b6c4eb69e8accf98357a72c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}